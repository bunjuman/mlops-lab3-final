{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943dd4a5",
   "metadata": {},
   "source": [
    "# Lab 3 - Advanced Cross-Validation & Reliable Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee009636",
   "metadata": {},
   "source": [
    "## Task 0: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9ca2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and Packages\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN \n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score, adjusted_rand_score, normalized_mutual_info_score, roc_auc_score, average_precision_score, f1_score, brier_score_loss\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# all the imports live here so I don't have to repeat them later\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# model + pipeline pieces\n",
    "from sklearn.datasets import load_breast_cancer, load_wine\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    RepeatedKFold,\n",
    "    RepeatedStratifiedKFold,\n",
    "    cross_val_score,\n",
    "    GridSearchCV\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151e45b4",
   "metadata": {},
   "source": [
    "## Task 1: Setup & baselines\n",
    "### Goal: Reminding what bad protocol looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ac69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading breast cancer dataset as a pandas frame\n",
    "bc = load_breast_cancer(as_frame=True)\n",
    "X_bc = bc.data\n",
    "y_bc = bc.target\n",
    "# loading wine dataset as a pandas frame\n",
    "wine = load_wine(as_frame=True)\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "# defining base pipelines for the three models\n",
    "pipe_lr = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, solver=\"lbfgs\"))\n",
    "])\n",
    "pipe_rf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "pipe_svc = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", SVC(\n",
    "        kernel=\"rbf\",\n",
    "        probability=True,\n",
    "        random_state=42\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa9796f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# small helper to evaluate a model under a given CV object and scoring\n",
    "def eval_cv(model, X, y, cv, scoring):\n",
    "    \"\"\"\n",
    "    Returns mean, std, and elapsed time for a given model/CV/scoring combo.\n",
    "    \"\"\"\n",
    "    start = time.perf_counter()\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    elapsed = time.perf_counter() - start\n",
    "    return scores.mean(), scores.std(), elapsed\n",
    "# global container so I can build a final results table later\n",
    "results_rows = []\n",
    "# helper to log one row into the global results list\n",
    "def log_result(dataset, model, cv_strategy, metric_mean, metric_std, time_sec, metric_name):\n",
    "    results_rows.append({\n",
    "        \"dataset\": dataset,\n",
    "        \"model\": model,\n",
    "        \"cv_strategy\": cv_strategy,\n",
    "        \"metric_name\": metric_name,\n",
    "        \"metric_mean\": metric_mean,\n",
    "        \"metric_std\": metric_std,\n",
    "        \"time_sec\": time_sec\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fafc1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer baseline logistic regression (single split)\n",
      "Test accuracy:  0.9824561403508771\n",
      "Test ROC-AUC:   0.9953703703703703\n",
      "Wine baseline logistic regression (single split)\n",
      "Test accuracy:  0.9722222222222222\n",
      "Test macro-F1:  0.9709618874773139\n"
     ]
    }
   ],
   "source": [
    "# doing a single 80/20 train/test split for breast cancer (stratified)\n",
    "X_bc_train, X_bc_test, y_bc_train, y_bc_test = train_test_split(\n",
    "    X_bc,\n",
    "    y_bc,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_bc\n",
    ")\n",
    "\n",
    "# doing a single 80/20 train/test split for wine (not necessarily stratified but could be)\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(\n",
    "    X_wine,\n",
    "    y_wine,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_wine\n",
    ")\n",
    "\n",
    "# creating a fresh logistic regression pipeline to use for both datasets\n",
    "baseline_lr = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "# fitting the baseline model on breast cancer train split\n",
    "baseline_lr.fit(X_bc_train, y_bc_train)\n",
    "\n",
    "# evaluating accuracy on the hold-out test split (breast cancer)\n",
    "y_bc_test_pred = baseline_lr.predict(X_bc_test)\n",
    "bc_test_acc = accuracy_score(y_bc_test, y_bc_test_pred)\n",
    "\n",
    "# evaluating ROC-AUC on the hold-out test split (breast cancer)\n",
    "y_bc_test_proba = baseline_lr.predict_proba(X_bc_test)[:, 1]\n",
    "bc_test_roc = roc_auc_score(y_bc_test, y_bc_test_proba)\n",
    "\n",
    "# refitting the same pipeline on the wine train split\n",
    "baseline_lr.fit(X_wine_train, y_wine_train)\n",
    "\n",
    "# evaluating accuracy on the hold-out test split (wine)\n",
    "y_wine_test_pred = baseline_lr.predict(X_wine_test)\n",
    "wine_test_acc = accuracy_score(y_wine_test, y_wine_test_pred)\n",
    "\n",
    "# evaluating macro-F1 on the hold-out test split (wine)\n",
    "wine_test_f1_macro = f1_score(\n",
    "    y_wine_test,\n",
    "    y_wine_test_pred,\n",
    "    average=\"macro\"\n",
    ")\n",
    "\n",
    "# printing baseline metrics so I can reference them in my writeup\n",
    "print(\"Breast Cancer baseline logistic regression (single split)\")\n",
    "print(f\"Test accuracy:  {bc_test_acc:}\")\n",
    "print(f\"Test ROC-AUC:   {bc_test_roc:}\")\n",
    "\n",
    "print(\"Wine baseline logistic regression (single split)\")\n",
    "print(f\"Test accuracy:  {wine_test_acc:}\")\n",
    "print(f\"Test macro-F1:  {wine_test_f1_macro:}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95b10d",
   "metadata": {},
   "source": [
    "### Task 1 Markdown - bad protocol\n",
    "\n",
    "We begin task 1 by importing the breast cancer and wine datasets. Then, we define base pipelines for each model. Each pipeline has a scaler step, where (like in lab 2) we use standard scaler to standardize each numeric feature of the data to a mean of 0 and a standard dewviation of 1. This keeps features on a comparable scale and is especially imporant for Logistic Regression and Support Vector Classification, which are sensitive to feature magnitudes. Then, each pipeline has a classifier step (clf), which all differ by pipeline. For LR, we use max iterations of 1000 while using the solver lbfgs, fitting a linear decision boundary in the scaled feature space, modeling log-odds of the positive class. We fit it with a large max iterations to give the optimizer room to converge, which means the loss is decreasing (scikit has loss as Logistic loss plus L2 regularization). For Random Forrest, we have 200 trees in the ensemble of desicion trees. This high number helps reduce variance while we set a random state for reproducable results. Fandom forrest doesn't strictly need scaling, but we keep it for consistecy across pipelines. For support vector classification, SVC(kernel=\"rbf\", probablity = True, random_state=42), we use a non linear SVM that can learn curved decision boundaries. THe RBF kernel is very sensitive to feature scale, and the StandardScaler step is critical. Here, the Radial Basis Function essentially means the SVM is using a Gaussian RBF kernel to measure how close points are to eachother  in the scaled feature space. Poitns that are close get high similarity and points that are far apart get near 0. This lets the model draw flexible, curved decision boundaries instead of just strait lines. Probability=True turns on the caliibratied probably outputs, which we need for ROC-AUC and other probability based metrics calculated later.\n",
    "\n",
    "Then, we create helpers that first evaluate a model under a given cross validation object, scoring it, and second a heper to log one row into the global results list.\n",
    "\n",
    "For the breast cancer data set, single split baseline, logistic regression on an 80/20 split gave accuracy around 0.982 and ROC-AUC around 0.995 on the test set. The metric this close to 1 means the model ranks malignant vs. benign cases very well on this one split. However, because this is a single random split on a slightly imbalanced dataset, these numbers could easily shift if this was a good or bad split. On the wine data, logistic regression reached test accuracy around 0.972 and macro-F1 around 0.971. Macro-F1 being fairly close to accuracy suggests the model is not completely ignoring any class, but again this is only one realization of the data split. Doing this all on a single split is risky because with small and imbalanced datasets, a single split can give high-variance estimates: a different random split might move accuracy/ROC-AUC by several points. The breast cancer dataset is slightly imbalanced, so a bad split could under-represent the minority class in either train or test, inflating accuracy but hiding bad minority-class performance. Because of this, a single split is not a reliable basis for picking models or tuning hyperparameters and thus we will try different methods of cross-validation to average over many different train/test partitions later in the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475dc83",
   "metadata": {},
   "source": [
    "## Task 2 - K-Fold & Stratified K-Fold\n",
    "### Goal: Show that using the wrong CV for classification gives unstable/biased estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8dab073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>cv_type</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>kf5_acc</td>\n",
       "      <td>0.977146</td>\n",
       "      <td>0.008964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>skf5_acc</td>\n",
       "      <td>0.973669</td>\n",
       "      <td>0.016627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>kf5_roc</td>\n",
       "      <td>0.994770</td>\n",
       "      <td>0.005573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>skf5_roc</td>\n",
       "      <td>0.995314</td>\n",
       "      <td>0.005345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>kf5_acc</td>\n",
       "      <td>0.988730</td>\n",
       "      <td>0.013805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wine</td>\n",
       "      <td>skf5_acc</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.013608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wine</td>\n",
       "      <td>kf5_roc_ovr</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wine</td>\n",
       "      <td>skf5_roc_ovr</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset       cv_type      mean       std\n",
       "0  breast_cancer       kf5_acc  0.977146  0.008964\n",
       "1  breast_cancer      skf5_acc  0.973669  0.016627\n",
       "2  breast_cancer       kf5_roc  0.994770  0.005573\n",
       "3  breast_cancer      skf5_roc  0.995314  0.005345\n",
       "4           wine       kf5_acc  0.988730  0.013805\n",
       "5           wine      skf5_acc  0.983333  0.013608\n",
       "6           wine   kf5_roc_ovr  0.999277  0.000987\n",
       "7           wine  skf5_roc_ovr  1.000000  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# small helper to evaluate a model under a CV object and scoring\n",
    "def eval_cv(model, X, y, cv, scoring):\n",
    "# Returns mean, std, and elapsed time for a given model/CV/scoring combo.\n",
    "    start = time.perf_counter()\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    elapsed = time.perf_counter() - start\n",
    "    return scores.mean(), scores.std(), elapsed\n",
    "#global table container so I can build a final results table later\n",
    "results_rows = []\n",
    "# helper to log one row into the global results list\n",
    "def log_result(dataset, model, cv_strategy, metric_mean, metric_std, time_sec, metric_name):\n",
    "    results_rows.append({\n",
    "        \"dataset\": dataset,\n",
    "        \"model\": model,\n",
    "        \"cv_strategy\": cv_strategy,\n",
    "        \"metric_name\": metric_name,\n",
    "        \"metric_mean\": metric_mean,\n",
    "        \"metric_std\": metric_std,\n",
    "        \"time_sec\": time_sec\n",
    "    })\n",
    "\n",
    "# reusing LR pipeline for cv comparisons\n",
    "cv_lr = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "#setting up 5 fold cv and stratified 5 fold (k fold) cv for breast cancer\n",
    "kf5_bc = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "skf5_bc = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# evaluating k fold on breast cancer for accuracy\n",
    "bc_kf_acc_mean, bc_kf_acc_std, bc_kf_acc_time = eval_cv(\n",
    "    cv_lr, X_bc, y_bc, kf5_bc, scoring=\"accuracy\"\n",
    ")\n",
    "# evaluating k fold on breast cancer for ROC-AUC\n",
    "bc_kf_roc_mean, bc_kf_roc_std, bc_kf_roc_time = eval_cv(\n",
    "    cv_lr, X_bc, y_bc, kf5_bc, scoring=\"roc_auc\"\n",
    ")\n",
    "# evaluating stratified k fold accuracy\n",
    "bc_skf_acc_mean, bc_skf_acc_std, bc_skf_acc_time = eval_cv(\n",
    "    cv_lr, X_bc, y_bc, skf5_bc, scoring=\"accuracy\"\n",
    ")\n",
    "# evaluating stratified k fold ROC-AUC\n",
    "bc_skf_roc_mean, bc_skf_roc_std, bc_skf_roc_time = eval_cv(\n",
    "    cv_lr, X_bc, y_bc, skf5_bc, scoring=\"roc_auc\"\n",
    ")\n",
    "\n",
    "#logging ROC-AUC results for breast cancer into the global table\n",
    "log_result(\n",
    "    dataset=\"breast_cancer\",\n",
    "    model=\"log_reg\",\n",
    "    cv_strategy=\"kfold_5\",\n",
    "    metric_mean=bc_kf_roc_mean,\n",
    "    metric_std=bc_kf_roc_std,\n",
    "    time_sec=bc_kf_roc_time,\n",
    "    metric_name=\"roc_auc\"\n",
    ")\n",
    "log_result(\n",
    "    dataset=\"breast_cancer\",\n",
    "    model=\"log_reg\",\n",
    "    cv_strategy=\"stratkfold_5\",\n",
    "    metric_mean=bc_skf_roc_mean,\n",
    "    metric_std=bc_skf_roc_std,\n",
    "    time_sec=bc_skf_roc_time,\n",
    "    metric_name=\"roc_auc\"\n",
    ")\n",
    "\n",
    "# setting up 5 fold and stratified 5 fold for wine\n",
    "kf5_wine = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "skf5_wine = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# evaluating k Fold on wine for accuracy\n",
    "wine_kf_acc_mean, wine_kf_acc_std, wine_kf_acc_time = eval_cv(\n",
    "    cv_lr, X_wine, y_wine, kf5_wine, scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "# evaluating k fold for ROC-AUC (one vs rest)\n",
    "wine_kf_roc_mean, wine_kf_roc_std, wine_kf_roc_time = eval_cv(\n",
    "    cv_lr, X_wine, y_wine, kf5_wine, scoring=\"roc_auc_ovr\"\n",
    ")\n",
    "\n",
    "# evaluating stratified k fold for accuracy\n",
    "wine_skf_acc_mean, wine_skf_acc_std, wine_skf_acc_time = eval_cv(\n",
    "    cv_lr, X_wine, y_wine, skf5_wine, scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "# evaluating stratified k fold for ROC-AUC (one-vs-rest)\n",
    "wine_skf_roc_mean, wine_skf_roc_std, wine_skf_roc_time = eval_cv(\n",
    "    cv_lr, X_wine, y_wine, skf5_wine, scoring=\"roc_auc_ovr\"\n",
    ")\n",
    "\n",
    "# logging primary ROC AUC results for wine into the global table\n",
    "log_result(\n",
    "    dataset=\"wine\",\n",
    "    model=\"log_reg\",\n",
    "    cv_strategy=\"kfold_5\",\n",
    "    metric_mean=wine_kf_roc_mean,\n",
    "    metric_std=wine_kf_roc_std,\n",
    "    time_sec=wine_kf_roc_time,\n",
    "    metric_name=\"roc_auc_ovr\"\n",
    ")\n",
    "log_result(\n",
    "    dataset=\"wine\",\n",
    "    model=\"log_reg\",\n",
    "    cv_strategy=\"stratkfold_5\",\n",
    "    metric_mean=wine_skf_roc_mean,\n",
    "    metric_std=wine_skf_roc_std,\n",
    "    time_sec=wine_skf_roc_time,\n",
    "    metric_name=\"roc_auc_ovr\"\n",
    ")\n",
    "\n",
    "# building a quick comparison table for the four evaluations\n",
    "cv_compare = pd.DataFrame({\n",
    "    \"dataset\": [\"breast_cancer\"] * 4 + [\"wine\"] * 4,\n",
    "    \"cv_type\": [\n",
    "        \"kf5_acc\", \"skf5_acc\", \"kf5_roc\", \"skf5_roc\",\n",
    "        \"kf5_acc\", \"skf5_acc\", \"kf5_roc_ovr\", \"skf5_roc_ovr\"\n",
    "    ],\n",
    "    \"mean\": [\n",
    "        bc_kf_acc_mean, bc_skf_acc_mean, bc_kf_roc_mean, bc_skf_roc_mean,\n",
    "        wine_kf_acc_mean, wine_skf_acc_mean, wine_kf_roc_mean, wine_skf_roc_mean\n",
    "    ],\n",
    "    \"std\": [\n",
    "        bc_kf_acc_std, bc_skf_acc_std, bc_kf_roc_std, bc_skf_roc_std,\n",
    "        wine_kf_acc_std, wine_skf_acc_std, wine_kf_roc_std, wine_skf_roc_std\n",
    "    ]\n",
    "})\n",
    "# showing the comparison table so we can inspect which metrics move the most\n",
    "display(cv_compare)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d26fcb",
   "metadata": {},
   "source": [
    "### Task 2 Markdown - using the right cross validation\n",
    "\n",
    " In Task 2, I compare plain K-Fold vs Stratified K-Fold on both the breast cancer and wine datasets. Unlike Task 1’s single 80 20 split, in this task we use 5 fold cross validation to average performance over multiple partitions and see how stratification changes the metrics and variability.\n",
    "\n",
    "Comparing accuracy in the breast cancer data, plain 5 fold K-Fold logistic regression reached an accuracy of about 0.977 +/- 0.009. StratifiedKFold(5) accuracy was roughly 0.974 +/- 0.017.\n",
    "\n",
    "For comparing ROC-AUC in the breast cancer data, plain K-Fold gave around 0.995 +/- 0.006. StratifiedKFold slightly improved this to about 0.995 +/1 0.004. The small drop in variance under stratification is underscores how ROC AUC is sensitive to how many positive examples appear in each fold, so keeping class ratios stable makes the ROC-AUC estimate more reliable.\n",
    "\n",
    "For the wine dataset, comparing accuracy across folds shows that plain 5-fold K-Fold reached about 0.989 +/- 0.014, while StratifiedKFold(5) produced roughly 0.983 +/- 0.014. The differences here are small, which makes sense given that the wine dataset is multiclass but not strongly imbalanced. Because the class proportions are already fairly even, stratification does not dramatically change how the folds behave, so accuracy remains similar across both CV strategies.\n",
    "\n",
    "For ROC-AUC(ovr) on the wine dataset, plain K-Fold produced a value around 0.999 ± 0.001, and StratifiedKFold increased this slightly to a perfect 1.000 ± 0.000. These nearly perfect AUC values highlight that the wine features are extremely separable for a linear classifier, and the dataset is small enough that folds contain very similar patterns. As a result, the model almost perfectly ranks the wine classes in every fold, regardless of whether stratification is applied.\n",
    "\n",
    "Now for which metric was most affected by stratification. Across the runs, the breast cancer ROC-AUC shows the clearest impact from stratification, especially in terms of variance shrinking when using StratifiedKFold instead of plain K-Fold. This matches the intuition that, on an imbalanced binary problem, metrics that depend on ranking positives vs negatives (like AUC) are most sensitive to how the minority class is distributed across folds. As we know, PR AUC focuses solely on the positive (minority) class and is highly sensitive to class imbalance, while ROC AUC provides an overall assessment across all classes and is less sensitive to imbalance\n",
    "\n",
    "Stratification matters here because stratifying the folds keeps the class proportions in each fold close to the original dataset, which is crucial for imbalanced problems like breast cancer.\n",
    "On breast cancer, this helps avoid folds that are almost all majority class, which would artificially inflate accuracy or destabilize AUC.\n",
    "On wine, stratification has a smaller effect but still provides slightly more consistent results, reinforcing that stratified CV is generally a safe default for classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233e476b",
   "metadata": {},
   "source": [
    "## Task 3 - Repeated (K-Fold & Stratified) + variance analysis\n",
    "### Goal: Show that one CV run is still a sample: repeating reduces variance & gives better model comparison.                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e825dbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>cv_strategy</th>\n",
       "      <th>mean_acc</th>\n",
       "      <th>std_acc</th>\n",
       "      <th>mean_roc</th>\n",
       "      <th>std_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>repeated_stratkfold_5x3</td>\n",
       "      <td>0.975972</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>0.994643</td>\n",
       "      <td>0.004763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>stratkfold_5</td>\n",
       "      <td>0.973669</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.995314</td>\n",
       "      <td>0.005345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>rand_forest</td>\n",
       "      <td>repeated_stratkfold_5x3</td>\n",
       "      <td>0.958397</td>\n",
       "      <td>0.019110</td>\n",
       "      <td>0.989861</td>\n",
       "      <td>0.009027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>rand_forest</td>\n",
       "      <td>stratkfold_5</td>\n",
       "      <td>0.954324</td>\n",
       "      <td>0.010166</td>\n",
       "      <td>0.989578</td>\n",
       "      <td>0.007703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wine</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>kfold_5</td>\n",
       "      <td>0.988730</td>\n",
       "      <td>0.013805</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wine</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>repeated_kfold_5x3</td>\n",
       "      <td>0.985026</td>\n",
       "      <td>0.017296</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wine</td>\n",
       "      <td>rand_forest</td>\n",
       "      <td>kfold_5</td>\n",
       "      <td>0.983175</td>\n",
       "      <td>0.022304</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.000466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wine</td>\n",
       "      <td>rand_forest</td>\n",
       "      <td>repeated_kfold_5x3</td>\n",
       "      <td>0.981376</td>\n",
       "      <td>0.021958</td>\n",
       "      <td>0.999108</td>\n",
       "      <td>0.002226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset        model              cv_strategy  mean_acc   std_acc  \\\n",
       "1  breast_cancer      log_reg  repeated_stratkfold_5x3  0.975972  0.012650   \n",
       "0  breast_cancer      log_reg             stratkfold_5  0.973669  0.016627   \n",
       "5  breast_cancer  rand_forest  repeated_stratkfold_5x3  0.958397  0.019110   \n",
       "4  breast_cancer  rand_forest             stratkfold_5  0.954324  0.010166   \n",
       "2           wine      log_reg                  kfold_5  0.988730  0.013805   \n",
       "3           wine      log_reg       repeated_kfold_5x3  0.985026  0.017296   \n",
       "6           wine  rand_forest                  kfold_5  0.983175  0.022304   \n",
       "7           wine  rand_forest       repeated_kfold_5x3  0.981376  0.021958   \n",
       "\n",
       "   mean_roc   std_roc  \n",
       "1  0.994643  0.004763  \n",
       "0  0.995314  0.005345  \n",
       "5  0.989861  0.009027  \n",
       "4  0.989578  0.007703  \n",
       "2  0.999277  0.000987  \n",
       "3  0.999601  0.000844  \n",
       "6  0.999767  0.000466  \n",
       "7  0.999108  0.002226  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#defining CV objects for breast cancer, a single split and a repeated stratified\n",
    "# 3 separate 5 fold cv runs\n",
    "skf5_bc = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rskf_bc = RepeatedStratifiedKFold(\n",
    "    n_splits=5,\n",
    "    n_repeats=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# defining CV objects for wine, a single split and a repeated stratified\n",
    "kf5_wine = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rkf_wine = RepeatedKFold(\n",
    "    n_splits=5,\n",
    "    n_repeats=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# storing models in a small dict so I can loop over them\n",
    "models = {\n",
    "    \"log_reg\": pipe_lr,\n",
    "    \"rand_forest\": pipe_rf\n",
    "}\n",
    "\n",
    "# container for a summary table across models / CV strategies\n",
    "rows_repeated = []\n",
    "\n",
    "#looping over models for breast cancer with single vs repeated stratified CV\n",
    "for model_name, model in models.items():\n",
    "    # single stratified 5-fold on breast cancer (accuracy)\n",
    "    bc_skf_acc_mean, bc_skf_acc_std, bc_skf_acc_time = eval_cv(\n",
    "        model, X_bc, y_bc, skf5_bc, scoring=\"accuracy\"\n",
    "    )\n",
    "    # single stratified 5-fold on breast cancer (ROC-AUC)\n",
    "    bc_skf_roc_mean, bc_skf_roc_std, bc_skf_roc_time = eval_cv(\n",
    "        model, X_bc, y_bc, skf5_bc, scoring=\"roc_auc\"\n",
    "    )\n",
    "\n",
    "    # repeated stratified 5x3 on breast cancer (accuracy)\n",
    "    bc_rskf_acc_mean, bc_rskf_acc_std, bc_rskf_acc_time = eval_cv(\n",
    "        model, X_bc, y_bc, rskf_bc, scoring=\"accuracy\"\n",
    "    )\n",
    "    # repeated stratified 5x3 on breast cancer (ROC-AUC)\n",
    "    bc_rskf_roc_mean, bc_rskf_roc_std, bc_rskf_roc_time = eval_cv(\n",
    "        model, X_bc, y_bc, rskf_bc, scoring=\"roc_auc\"\n",
    "    )\n",
    "\n",
    "    # logging ROC-AUC results for breast cancer into the global results table\n",
    "    log_result(\n",
    "        dataset=\"breast_cancer\",\n",
    "        model=model_name,\n",
    "        cv_strategy=\"stratkfold_5\",\n",
    "        metric_mean=bc_skf_roc_mean,\n",
    "        metric_std=bc_skf_roc_std,\n",
    "        time_sec=bc_skf_roc_time,\n",
    "        metric_name=\"roc_auc\"\n",
    "    )\n",
    "    log_result(\n",
    "        dataset=\"breast_cancer\",\n",
    "        model=model_name,\n",
    "        cv_strategy=\"repeated_stratkfold_5x3\",\n",
    "        metric_mean=bc_rskf_roc_mean,\n",
    "        metric_std=bc_rskf_roc_std,\n",
    "        time_sec=bc_rskf_roc_time,\n",
    "        metric_name=\"roc_auc\"\n",
    "    )\n",
    "\n",
    "    # adding breast cancer rows to the repeated-CV summary\n",
    "    rows_repeated.append({\n",
    "        \"dataset\": \"breast_cancer\",\n",
    "        \"model\": model_name,\n",
    "        \"cv_strategy\": \"stratkfold_5\",\n",
    "        \"mean_acc\": bc_skf_acc_mean,\n",
    "        \"std_acc\": bc_skf_acc_std,\n",
    "        \"mean_roc\": bc_skf_roc_mean,\n",
    "        \"std_roc\": bc_skf_roc_std\n",
    "    })\n",
    "    rows_repeated.append({\n",
    "        \"dataset\": \"breast_cancer\",\n",
    "        \"model\": model_name,\n",
    "        \"cv_strategy\": \"repeated_stratkfold_5x3\",\n",
    "        \"mean_acc\": bc_rskf_acc_mean,\n",
    "        \"std_acc\": bc_rskf_acc_std,\n",
    "        \"mean_roc\": bc_rskf_roc_mean,\n",
    "        \"std_roc\": bc_rskf_roc_std\n",
    "    })\n",
    "\n",
    "    # single K-Fold on wine (accuracy)\n",
    "    wine_kf_acc_mean, wine_kf_acc_std, wine_kf_acc_time = eval_cv(\n",
    "        model, X_wine, y_wine, kf5_wine, scoring=\"accuracy\"\n",
    "    )\n",
    "    # single K-Fold on wine (ROC-AUC one-vs-rest)\n",
    "    wine_kf_roc_mean, wine_kf_roc_std, wine_kf_roc_time = eval_cv(\n",
    "        model, X_wine, y_wine, kf5_wine, scoring=\"roc_auc_ovr\"\n",
    "    )\n",
    "\n",
    "    # repeated K-Fold on wine (accuracy)\n",
    "    wine_rkf_acc_mean, wine_rkf_acc_std, wine_rkf_acc_time = eval_cv(\n",
    "        model, X_wine, y_wine, rkf_wine, scoring=\"accuracy\"\n",
    "    )\n",
    "    # repeated K-Fold on wine (ROC-AUC one-vs-rest)\n",
    "    wine_rkf_roc_mean, wine_rkf_roc_std, wine_rkf_roc_time = eval_cv(\n",
    "        model, X_wine, y_wine, rkf_wine, scoring=\"roc_auc_ovr\"\n",
    "    )\n",
    "\n",
    "    # logging ROC-AUC results for wine into the global results table\n",
    "    log_result(\n",
    "        dataset=\"wine\",\n",
    "        model=model_name,\n",
    "        cv_strategy=\"kfold_5\",\n",
    "        metric_mean=wine_kf_roc_mean,\n",
    "        metric_std=wine_kf_roc_std,\n",
    "        time_sec=wine_kf_roc_time,\n",
    "        metric_name=\"roc_auc_ovr\"\n",
    "    )\n",
    "    log_result(\n",
    "        dataset=\"wine\",\n",
    "        model=model_name,\n",
    "        cv_strategy=\"repeated_kfold_5x3\",\n",
    "        metric_mean=wine_rkf_roc_mean,\n",
    "        metric_std=wine_rkf_roc_std,\n",
    "        time_sec=wine_rkf_roc_time,\n",
    "        metric_name=\"roc_auc_ovr\"\n",
    "    )\n",
    "\n",
    "    # adding wine rows to the repeated-CV summary\n",
    "    rows_repeated.append({\n",
    "        \"dataset\": \"wine\",\n",
    "        \"model\": model_name,\n",
    "        \"cv_strategy\": \"kfold_5\",\n",
    "        \"mean_acc\": wine_kf_acc_mean,\n",
    "        \"std_acc\": wine_kf_acc_std,\n",
    "        \"mean_roc\": wine_kf_roc_mean,\n",
    "        \"std_roc\": wine_kf_roc_std\n",
    "    })\n",
    "    rows_repeated.append({\n",
    "        \"dataset\": \"wine\",\n",
    "        \"model\": model_name,\n",
    "        \"cv_strategy\": \"repeated_kfold_5x3\",\n",
    "        \"mean_acc\": wine_rkf_acc_mean,\n",
    "        \"std_acc\": wine_rkf_acc_std,\n",
    "        \"mean_roc\": wine_rkf_roc_mean,\n",
    "        \"std_roc\": wine_rkf_roc_std\n",
    "    })\n",
    "\n",
    "#turning the collected rows into a DataFrame\n",
    "repeated_summary = pd.DataFrame(rows_repeated)\n",
    "#sorting by dataset, then model, then CV strategy\n",
    "repeated_summary = repeated_summary.sort_values(\n",
    "    by=[\"dataset\", \"model\", \"cv_strategy\"]\n",
    ")\n",
    "display(repeated_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac233c0",
   "metadata": {},
   "source": [
    "### Task 3 Markdown - using the right cross validation\n",
    "\n",
    "In Task 3, I compare single stratified CV to repeated stratified CV (5x3) on the breast cancer dataset, and single K-Fold to repeated K-Fold (5x3) on the wine dataset. The goal is to see how repeating CV changes the mean and variability of accuracy and ROC-AUC, and whether it changes the relative ranking between logistic regression and random forest.\n",
    "\n",
    "For breast cancer with logistic regression, single StratifiedKFold(5) gave accuracy around 0.974 +/- 0.017 and ROC-AUC around 0.995 +/- 0.005. RepeatedStratifiedKFold(5x3) produced accuracy around 0.976 +/- 0.013 and ROC-AUC around 0.995 +/- 0.005. The means are very similar, but the standard deviation for accuracy shrinks slightly under repeated CV, which makes the performance estimate a bit more stable across different train/test splits.\n",
    "\n",
    "For breast cancer with random forest, StratifiedKFold(5) reached accuracy of about 0.954 +/- 0.010 and ROC-AUC of roughly 0.990 +/- 0.008. RepeatedStratifiedKFold(5x3) increased accuracy to about 0.958 +/- 0.019 and ROC-AUC to about 0.990 +/- 0.009. Here the mean accuracy nudges upward, but the standard deviations do not consistently drop, reminding me that repeated CV reduces variance on average but individual runs can still bounce around a bit.\n",
    "\n",
    "On the wine dataset with logistic regression, single KFold(5) gave accuracy of about 0.989 +/- 0.014 and ROC-AUC(ovr) of about 0.999 +/- 0.001. RepeatedKFold(5x3) gave accuracy around 0.985 +/- 0.017 and ROC-AUC(ovr) around 1.000 +/- 0.001. The average performance is essentially unchanged, but repeated CV smooths the ROC-AUC variability slightly, which is expected on a small but very separable dataset.\n",
    "\n",
    "For wine with random forest, KFold(5) produced accuracy around 0.983 +/- 0.022 and ROC-AUC(ovr) around 1.000 +/- 0.0005, while RepeatedKFold(5x3) gave accuracy around 0.981 +/- 0.022 and ROC-AUC(ovr) around 0.999 +/- 0.002. In this case, repeating CV does not dramatically change either the means or the standard deviations, which fits the idea that the wine classes are already easy to separate and the model is near its performance ceiling.\n",
    "\n",
    "Overall, repeated CV does not radically change the average scores, but it gives me more observations of how each model behaves across different splits. On breast cancer, it reinforces that logistic regression is slightly ahead of random forest in ROC-AUC, and on wine, it confirms that both models perform extremely well and are very close. The main value of repeated CV here is that it makes the ranking of models less dependent on the luck of a single CV partition, even if the standard deviations do not always shrink in every single metric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776690b",
   "metadata": {},
   "source": [
    "## Task 4 - Nested CV for hyperparameter tuning\n",
    "### Goal: teach the “inner loop tunes, outer loop estimates generalization.” No peeking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d240becf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV results on breast cancer (ROC-AUC):\n",
      "  Pipeline A (LogReg): mean=0.994, std=0.010\n",
      "  Pipeline B (SVC RBF): mean=0.995, std=0.006\n",
      "\n",
      "Chosen hyperparameters per outer fold for Pipeline A:\n",
      "  Fold 1: {'clf__C': 0.1}\n",
      "  Fold 2: {'clf__C': 0.1}\n",
      "  Fold 3: {'clf__C': 10.0}\n",
      "  Fold 4: {'clf__C': 0.1}\n",
      "  Fold 5: {'clf__C': 1.0}\n",
      "\n",
      "Chosen hyperparameters per outer fold for Pipeline B:\n",
      "  Fold 1: {'clf__C': 1.0, 'clf__gamma': 'scale'}\n",
      "  Fold 2: {'clf__C': 1.0, 'clf__gamma': 'scale'}\n",
      "  Fold 3: {'clf__C': 10.0, 'clf__gamma': 'scale'}\n",
      "  Fold 4: {'clf__C': 1.0, 'clf__gamma': 'scale'}\n",
      "  Fold 5: {'clf__C': 1.0, 'clf__gamma': 'scale'}\n",
      "\n",
      "Non-nested estimate for Pipeline A:\n",
      "  GridSearchCV best_score_ (inner CV only): 0.9945093530369894\n"
     ]
    }
   ],
   "source": [
    "#pipeline A: logistic regression inside a pipeline\n",
    "pipeA = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "# grid for pipe A (logistic regression C values)\n",
    "param_grid_A = {\n",
    "    \"clf__C\": [0.01, 0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "#pipe B: SVC with RBF kernel inside a pipeline\n",
    "pipeB = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", SVC(kernel=\"rbf\", probability=True, random_state=42))\n",
    "])\n",
    "# grid for pipeline B (C and gamma)\n",
    "param_grid_B = {\n",
    "    \"clf__C\": [0.1, 1.0, 10.0],\n",
    "    \"clf__gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "# setting up outer stratified 5-fold CV - generalization estimate\n",
    "outer_cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "# setting up inner stratified 3-fold CV - hyperparameter tuning\n",
    "inner_cv = StratifiedKFold(\n",
    "    n_splits=3,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# helper function to run nested CV for a given pipeline and param grid\n",
    "def run_nested_cv(pipeline, param_grid, X, y, outer_cv, inner_cv, scoring=\"roc_auc\"):\n",
    "    \"\"\"\n",
    "    Runs nested CV: inner GridSearchCV for tuning, outer loop for generalization.\n",
    "    Returns outer scores, chosen params per outer fold, and total elapsed time.\n",
    "    \"\"\"\n",
    "    outer_scores = []\n",
    "    chosen_params = []\n",
    "    start_total = time.perf_counter()\n",
    "\n",
    "    for train_idx, test_idx in outer_cv.split(X, y):\n",
    "        # splitting into outer train/test for this fold\n",
    "        X_tr, X_te = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_tr, y_te = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # setting up grid search with the inner CV\n",
    "        grid = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=param_grid,\n",
    "            cv=inner_cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # fitting the grid on the outer training fold\n",
    "        grid.fit(X_tr, y_tr)\n",
    "\n",
    "        # getting predicted probabilities from the best model for ROC-AUC\n",
    "        y_proba = grid.best_estimator_.predict_proba(X_te)[:, 1]\n",
    "\n",
    "        # computing ROC-AUC on the outer test fold\n",
    "        score = roc_auc_score(y_te, y_proba)\n",
    "        outer_scores.append(score)\n",
    "\n",
    "        # storing the best hyperparameters for this outer fold\n",
    "        chosen_params.append(grid.best_params_)\n",
    "\n",
    "    elapsed_total = time.perf_counter() - start_total\n",
    "    return np.array(outer_scores), chosen_params, elapsed_total\n",
    "\n",
    "# running nested CV for pipeline A (logistic regression)\n",
    "outer_scores_A, chosen_params_A, elapsed_A = run_nested_cv(\n",
    "    pipeA, param_grid_A, X_bc, y_bc, outer_cv, inner_cv, scoring=\"roc_auc\"\n",
    ")\n",
    "# running nested CV for pipeline B (SVC with RBF)\n",
    "outer_scores_B, chosen_params_B, elapsed_B = run_nested_cv(\n",
    "    pipeB, param_grid_B, X_bc, y_bc, outer_cv, inner_cv, scoring=\"roc_auc\"\n",
    ")\n",
    "# computing mean and std of outer ROC-AUC for both pipelines\n",
    "A_mean, A_std = outer_scores_A.mean(), outer_scores_A.std()\n",
    "B_mean, B_std = outer_scores_B.mean(), outer_scores_B.std()\n",
    "# logging nested CV results into the global table\n",
    "log_result(\n",
    "    dataset=\"breast_cancer\",\n",
    "    model=\"log_reg_nested\",\n",
    "    cv_strategy=\"nested_stratkfold_5x3\",\n",
    "    metric_mean=A_mean,\n",
    "    metric_std=A_std,\n",
    "    time_sec=elapsed_A,\n",
    "    metric_name=\"roc_auc\"\n",
    ")\n",
    "log_result(\n",
    "    dataset=\"breast_cancer\",\n",
    "    model=\"svc_nested\",\n",
    "    cv_strategy=\"nested_stratkfold_5x3\",\n",
    "    metric_mean=B_mean,\n",
    "    metric_std=B_std,\n",
    "    time_sec=elapsed_B,\n",
    "    metric_name=\"roc_auc\"\n",
    ")\n",
    "\n",
    "# printing nested CV results and chosen hyperparameters per outer fold\n",
    "print(\"Nested CV results on breast cancer (ROC-AUC):\")\n",
    "print(f\"  Pipeline A (LogReg): mean={A_mean:.3f}, std={A_std:.3f}\")\n",
    "print(f\"  Pipeline B (SVC RBF): mean={B_mean:.3f}, std={B_std:.3f}\\n\")\n",
    "print(\"Chosen hyperparameters per outer fold for Pipeline A:\")\n",
    "for i, params in enumerate(chosen_params_A, start=1):\n",
    "    print(f\"  Fold {i}: {params}\")\n",
    "print(\"\\nChosen hyperparameters per outer fold for Pipeline B:\")\n",
    "for i, params in enumerate(chosen_params_B, start=1):\n",
    "    print(f\"  Fold {i}: {params}\")\n",
    "# computing a non-nested (over-optimistic) estimate using GridSearchCV on full data\n",
    "grid_non_nested_A = GridSearchCV(\n",
    "    pipeA,\n",
    "    param_grid_A,\n",
    "    cv=inner_cv,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fitting on the full breast cancer dataset - the \"wrong\" method\n",
    "grid_non_nested_A.fit(X_bc, y_bc)\n",
    "\n",
    "# taking the best_score_ from the inner CV as the non-nested estimate\n",
    "non_nested_A_score = grid_non_nested_A.best_score_\n",
    "\n",
    "print(\"\\nNon-nested estimate for Pipeline A:\")\n",
    "print(f\"  GridSearchCV best_score_ (inner CV only): {non_nested_A_score:}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bc4ad3",
   "metadata": {},
   "source": [
    "### Task 4 Markdown - nesting! and not nesting\n",
    "\n",
    "After running nested cross validation on the breast cancer dataset, for Pipeline A (LogReg), nested StratifiedKFold (5 outer, 3 inner) gave ROC-AUC around 0.994 +/- 0.010. For Pipeline B's support vector classifier with RBF, nested StratifiedKFold gave ROC-AUC around 0.995 +/- 0.006. Both scores are very close to 1.0, which means both pipelines separate malignant vs benign cases extremely well. the small gap between 0.994 and 0.995 is likely within normal sampling noise rather than a big practical difference.\n",
    "\n",
    "After running hyperparameter stability across outer folds, for Logistic Regression, the best C from the inner loop changed by outer fold. It was C = 0.1 in most folds, C = 10.0 once, and C = 1.0 once. This variation suggests that several C values lie on a relatively flat performance plateau. The change in the regularization strength within this range does not dramatically move ROC-AUC, even though the optimizer locks onto slightly different values per fold. For SVC, the best hyperparameters were very stable. Every outer fold chose C = 1.0 and gamma = \"scale\". This indicates a consistent sweet spot for this model under this CV setup.\n",
    "\n",
    "For non-nested vs nested setups for pipelines, the non-nested GridSearchCV estimate for Pipeline A (using best_score_ from the inner CV only) was ROC-AUC around 0.995, slightly higher than the nested mean of about 0.994. Even though the difference is small, the non-nested estimate is optimistic because the same data is used both to pick hyperparameters and to report performance (:/). The nested estimate 0.994 +/- 0.010 keeps tuning and evaluation strictly separated (inner loop tunes, outer loop evaluates), so this is the number is the value we should trust when reporting results or choosing a model for deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ce42df",
   "metadata": {},
   "source": [
    "## Task 5 - Nested CV + feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3813da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV with feature selection (RandomForest + SelectKBest):\n",
      "  Mean ROC-AUC: 0.990\n",
      "  Std ROC-AUC:  0.008\n",
      "\n",
      "Chosen hyperparameters per outer fold:\n",
      "  Fold 1: {'clf__max_depth': None, 'clf__n_estimators': 300, 'select__k': 'all'}\n",
      "  Fold 2: {'clf__max_depth': None, 'clf__n_estimators': 300, 'select__k': 'all'}\n",
      "  Fold 3: {'clf__max_depth': 5, 'clf__n_estimators': 300, 'select__k': 'all'}\n",
      "  Fold 4: {'clf__max_depth': 5, 'clf__n_estimators': 100, 'select__k': 'all'}\n",
      "  Fold 5: {'clf__max_depth': 5, 'clf__n_estimators': 300, 'select__k': 'all'}\n",
      "\n",
      "Frequency of selected k values across outer folds:\n",
      "all    5\n",
      "Name: count, dtype: int64\n",
      "WRONG pattern (FS before CV on full data):\n",
      "  ROC-AUC (leaky): 0.9849559783333941 ± 0.010715329994244767\n"
     ]
    }
   ],
   "source": [
    "# building a pipeline that includes feature selection and random forest\n",
    "pipe_fs = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"select\", SelectKBest(score_func=f_classif)),\n",
    "    (\"clf\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "#defining the search space for k and RF hyperparameters\n",
    "param_grid_fs = {\n",
    "    #how many features\n",
    "    \"select__k\": [5, 10, 15, \"all\"],\n",
    "    #how many trees\n",
    "    \"clf__n_estimators\": [100, 300],\n",
    "    #how deep each tree can go, none meaning trees can grow until pure\n",
    "    \"clf__max_depth\": [None, 5, 10]\n",
    "}\n",
    "\n",
    "# running nested CV on breast cancer with feature selection inside the pipeline\n",
    "fs_scores_nested, fs_params_nested, fs_elapsed = run_nested_cv(\n",
    "    pipe_fs,\n",
    "    param_grid_fs,\n",
    "    X_bc,\n",
    "    y_bc,\n",
    "    outer_cv,\n",
    "    inner_cv,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n",
    "#computing mean and std of nested ROC-AUC with feature selection\n",
    "fs_nested_mean = fs_scores_nested.mean()\n",
    "fs_nested_std = fs_scores_nested.std()\n",
    "# logging nested and FS result into global results table\n",
    "log_result(\n",
    "    dataset=\"breast_cancer\",\n",
    "    model=\"rf_fs_nested\",\n",
    "    cv_strategy=\"nested_stratkfold_5x3\",\n",
    "    metric_mean=fs_nested_mean,\n",
    "    metric_std=fs_nested_std,\n",
    "    time_sec=fs_elapsed,\n",
    "    metric_name=\"roc_auc\"\n",
    ")\n",
    "# printing nested CV + feature selection results\n",
    "print(\"Nested CV with feature selection (RandomForest + SelectKBest):\")\n",
    "print(f\"  Mean ROC-AUC: {fs_nested_mean:}\")\n",
    "print(f\"  Std ROC-AUC:  {fs_nested_std:}\\n\")\n",
    "\n",
    "print(\"Chosen hyperparameters per outer fold:\")\n",
    "for i, params in enumerate(fs_params_nested, start=1):\n",
    "    print(f\"  Fold {i}: {params}\")\n",
    "\n",
    "# collecting how often each k value was selected\n",
    "k_values = [p[\"select__k\"] for p in fs_params_nested]\n",
    "k_counts = pd.Series(k_values).value_counts()\n",
    "print(\"\\nFrequency of selected k values across outer folds:\")\n",
    "print(k_counts)\n",
    "\n",
    "# trying the wrong way, feature selection on full data first, then CV\n",
    "selector_wrong = SelectKBest(score_func=f_classif, k=10)\n",
    "\n",
    "# fitting the selector on the full dataset (this leaks label information)\n",
    "selector_wrong.fit(X_bc, y_bc)\n",
    "\n",
    "# transforming the full dataset using selected features\n",
    "X_bc_fs = selector_wrong.transform(X_bc)\n",
    "\n",
    "# building a pipeline without feature selection (since it's already applied)\n",
    "pipe_rf_no_fs = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# running plain StratifiedKFold CV on the already feature-selected data (wrong)\n",
    "skf5_bc = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_wrong_scores, rf_wrong_std, rf_wrong_time = eval_cv(\n",
    "    pipe_rf_no_fs,\n",
    "    pd.DataFrame(X_bc_fs),\n",
    "    y_bc,\n",
    "    skf5_bc,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n",
    "print(\"WRONG pattern (FS before CV on full data):\")\n",
    "print(f\"  ROC-AUC (leaky): {rf_wrong_scores:} ± {rf_wrong_std:}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d08f377",
   "metadata": {},
   "source": [
    "### Task 5 Markdown - More nesting, expanded pipeline building, what not to do\n",
    "\n",
    "In Task 5, we extend the nested CV setup by adding feature selection into the pipeline. Our methodology here is StandardScaler to SelectKBest(f_classif) to RandomForestClassifier. The idea is to tune both the number of selected features and the random forest hyperparameters inside the inner CV loop, and then estimate generalization with the outer loop. Under the correct nested setup, the RandomForest + SelectKBest pipeline reached a mean ROC-AUC of about 0.990 +/- 0.008 on the breast cancer data. This score is very close to 1, which means the tuned pipeline is ranking malignant vs benign cases quite well across outer folds, but there is still a bit of fold-to-fold variability reflected in the standard deviation.\n",
    "\n",
    "When we look at the chosen hyperparameters per outer fold, we see that n_estimators is always 300, and select__k is always \"all\", while max_depth flips between None for the first two folds and 5 for the last three folds. This pattern suggests that the model is relatively insensitive to the exact depth setting as long as the forest is reasonably large, and that in this dataset keeping all features works slightly better than aggressively cutting down to a small subset.\n",
    "\n",
    "The frequency table for select__k shows that \"all\" was chosen in 5 out of 5 outer folds. This tells me that, according to the nested CV search, using every feature tends to give the best ROC-AUC on this particular dataset, even though I allowed the search to consider k values like 5, 10, and 15.\n",
    "\n",
    "For the wrong pattern, I first ran SelectKBest on the full dataset and then did StratifiedKFold on the already reduced features. This leaky setup produced a ROC-AUC of about 0.985 +/- 0.011. Even though 0.985 sounds strong, it is not directly comparable to the nested result because the feature selector has already seen all labels, including those in the CV test folds.\n",
    "\n",
    "The key takeaway is that the nested CV with feature selection inside the pipeline provides a slightly higher and more trustworthy ROC-AUC estimate than the leaky approach. Any label-dependent step like SelectKBest must live inside the inner CV loop. Doing feature selection once on the full dataset before CV leads to optimistic performance estimates that would not hold up on truly unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d20bc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>cv_strategy</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_mean</th>\n",
       "      <th>metric_std</th>\n",
       "      <th>time_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>kfold_5</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.994770</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>0.802109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>repeated_stratkfold_5x3</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.994643</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>0.030671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>stratkfold_5</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.995314</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.787515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>stratkfold_5</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.995314</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.015047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>log_reg_nested</td>\n",
       "      <td>nested_stratkfold_5x3</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.009728</td>\n",
       "      <td>0.217222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>rand_forest</td>\n",
       "      <td>repeated_stratkfold_5x3</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.989861</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>0.527414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>rand_forest</td>\n",
       "      <td>stratkfold_5</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.989578</td>\n",
       "      <td>0.007703</td>\n",
       "      <td>0.342995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>rf_fs_nested</td>\n",
       "      <td>nested_stratkfold_5x3</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>7.649145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>svc_nested</td>\n",
       "      <td>nested_stratkfold_5x3</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.994525</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.309485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wine</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>kfold_5</td>\n",
       "      <td>roc_auc_ovr</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.622545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wine</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>kfold_5</td>\n",
       "      <td>roc_auc_ovr</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.031068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wine</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>repeated_kfold_5x3</td>\n",
       "      <td>roc_auc_ovr</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.045315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wine</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>stratkfold_5</td>\n",
       "      <td>roc_auc_ovr</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wine</td>\n",
       "      <td>rand_forest</td>\n",
       "      <td>kfold_5</td>\n",
       "      <td>roc_auc_ovr</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.203397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wine</td>\n",
       "      <td>rand_forest</td>\n",
       "      <td>repeated_kfold_5x3</td>\n",
       "      <td>roc_auc_ovr</td>\n",
       "      <td>0.999108</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.292992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset           model              cv_strategy  metric_name  \\\n",
       "0   breast_cancer         log_reg                  kfold_5      roc_auc   \n",
       "5   breast_cancer         log_reg  repeated_stratkfold_5x3      roc_auc   \n",
       "1   breast_cancer         log_reg             stratkfold_5      roc_auc   \n",
       "4   breast_cancer         log_reg             stratkfold_5      roc_auc   \n",
       "12  breast_cancer  log_reg_nested    nested_stratkfold_5x3      roc_auc   \n",
       "9   breast_cancer     rand_forest  repeated_stratkfold_5x3      roc_auc   \n",
       "8   breast_cancer     rand_forest             stratkfold_5      roc_auc   \n",
       "14  breast_cancer    rf_fs_nested    nested_stratkfold_5x3      roc_auc   \n",
       "13  breast_cancer      svc_nested    nested_stratkfold_5x3      roc_auc   \n",
       "2            wine         log_reg                  kfold_5  roc_auc_ovr   \n",
       "6            wine         log_reg                  kfold_5  roc_auc_ovr   \n",
       "7            wine         log_reg       repeated_kfold_5x3  roc_auc_ovr   \n",
       "3            wine         log_reg             stratkfold_5  roc_auc_ovr   \n",
       "10           wine     rand_forest                  kfold_5  roc_auc_ovr   \n",
       "11           wine     rand_forest       repeated_kfold_5x3  roc_auc_ovr   \n",
       "\n",
       "    metric_mean  metric_std  time_sec  \n",
       "0      0.994770    0.005573  0.802109  \n",
       "5      0.994643    0.004763  0.030671  \n",
       "1      0.995314    0.005345  0.787515  \n",
       "4      0.995314    0.005345  0.015047  \n",
       "12     0.993590    0.009728  0.217222  \n",
       "9      0.989861    0.009027  0.527414  \n",
       "8      0.989578    0.007703  0.342995  \n",
       "14     0.990070    0.007646  7.649145  \n",
       "13     0.994525    0.005980  0.309485  \n",
       "2      0.999277    0.000987  0.622545  \n",
       "6      0.999277    0.000987  0.031068  \n",
       "7      0.999601    0.000844  0.045315  \n",
       "3      1.000000    0.000000  0.015067  \n",
       "10     0.999767    0.000466  0.203397  \n",
       "11     0.999108    0.002226  0.292992  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>cv_strategy</th>\n",
       "      <th>mean_metric</th>\n",
       "      <th>std_metric</th>\n",
       "      <th>mean_time_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>repeated_stratkfold_5x3</td>\n",
       "      <td>0.994643</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>0.030671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>stratkfold_5</td>\n",
       "      <td>0.995314</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.401281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>kfold_5</td>\n",
       "      <td>0.994770</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>0.802109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>log_reg_nested</td>\n",
       "      <td>nested_stratkfold_5x3</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.009728</td>\n",
       "      <td>0.217222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>rand_forest</td>\n",
       "      <td>stratkfold_5</td>\n",
       "      <td>0.989578</td>\n",
       "      <td>0.007703</td>\n",
       "      <td>0.342995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>rand_forest</td>\n",
       "      <td>repeated_stratkfold_5x3</td>\n",
       "      <td>0.989861</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>0.527414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>rf_fs_nested</td>\n",
       "      <td>nested_stratkfold_5x3</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>7.649145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>svc_nested</td>\n",
       "      <td>nested_stratkfold_5x3</td>\n",
       "      <td>0.994525</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.309485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wine</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>stratkfold_5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wine</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>repeated_kfold_5x3</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.045315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wine</td>\n",
       "      <td>log_reg</td>\n",
       "      <td>kfold_5</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.326806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wine</td>\n",
       "      <td>rand_forest</td>\n",
       "      <td>kfold_5</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.203397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wine</td>\n",
       "      <td>rand_forest</td>\n",
       "      <td>repeated_kfold_5x3</td>\n",
       "      <td>0.999108</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.292992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset           model              cv_strategy  mean_metric  \\\n",
       "1   breast_cancer         log_reg  repeated_stratkfold_5x3     0.994643   \n",
       "2   breast_cancer         log_reg             stratkfold_5     0.995314   \n",
       "0   breast_cancer         log_reg                  kfold_5     0.994770   \n",
       "3   breast_cancer  log_reg_nested    nested_stratkfold_5x3     0.993590   \n",
       "5   breast_cancer     rand_forest             stratkfold_5     0.989578   \n",
       "4   breast_cancer     rand_forest  repeated_stratkfold_5x3     0.989861   \n",
       "6   breast_cancer    rf_fs_nested    nested_stratkfold_5x3     0.990070   \n",
       "7   breast_cancer      svc_nested    nested_stratkfold_5x3     0.994525   \n",
       "10           wine         log_reg             stratkfold_5     1.000000   \n",
       "9            wine         log_reg       repeated_kfold_5x3     0.999601   \n",
       "8            wine         log_reg                  kfold_5     0.999277   \n",
       "11           wine     rand_forest                  kfold_5     0.999767   \n",
       "12           wine     rand_forest       repeated_kfold_5x3     0.999108   \n",
       "\n",
       "    std_metric  mean_time_sec  \n",
       "1     0.004763       0.030671  \n",
       "2     0.005345       0.401281  \n",
       "0     0.005573       0.802109  \n",
       "3     0.009728       0.217222  \n",
       "5     0.007703       0.342995  \n",
       "4     0.009027       0.527414  \n",
       "6     0.007646       7.649145  \n",
       "7     0.005980       0.309485  \n",
       "10    0.000000       0.015067  \n",
       "9     0.000844       0.045315  \n",
       "8     0.000987       0.326806  \n",
       "11    0.000466       0.203397  \n",
       "12    0.002226       0.292992  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# turning the accumulated global results into a DataFrame\n",
    "results_df = pd.DataFrame(results_rows)\n",
    "\n",
    "# quick look at the combined results table\n",
    "display(results_df.sort_values(by=[\"dataset\", \"model\", \"cv_strategy\"]))\n",
    "\n",
    "# example: finding the most reliable (lowest std) strategy per dataset/model\n",
    "reliability_summary = (\n",
    "    results_df\n",
    "    .groupby([\"dataset\", \"model\", \"cv_strategy\"])\n",
    "    .agg(\n",
    "        mean_metric=(\"metric_mean\", \"mean\"),\n",
    "        std_metric=(\"metric_std\", \"mean\"),\n",
    "        mean_time_sec=(\"time_sec\", \"mean\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# sorting so I can see which strategies have the smallest std for each dataset/model\n",
    "reliability_summary = reliability_summary.sort_values(\n",
    "    by=[\"dataset\", \"model\", \"std_metric\"]\n",
    ")\n",
    "\n",
    "display(reliability_summary)\n",
    "\n",
    "# exporting the results table to CSV for submission\n",
    "results_df.to_csv(\"cv_results_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57643a0",
   "metadata": {},
   "source": [
    "### Task 6 Markdown - Pulling everything together\n",
    "\n",
    "In Task 6, we pull everything together into one table with columns (dataset, model, cv_strategy, metric_name, metric_mean, metric_std, time_sec). This combines the earlier experiments from Tasks 2–5 and allows us to compare hollistically not just performance, but also variability and compute cost across K-Fold, StratifiedKFold, Repeated CV, and Nested CV.\n",
    "\n",
    "On the breast cancer dataset with logistic regression, the ROC-AUC under plain KFold(5) was about 0.995 +/- 0.006 with a runtime around 5 seconds, StratifiedKFold(5) was about 0.996 +/- 0.005 in roughly 4 seconds, and RepeatedStratifiedKFold(5x3) was about 0.995 +/- 0.005 in under 0.1 seconds. Nested stratified CV gave a slightly lower mean of around 0.994 +/- 0.010 and took on around 16 seconds. This pattern shows that nested CV is the slowest but most honest estimate, while repeated stratified CV gives almost the same mean AUC as the best non-nested strategy, with a small standard deviation and very low runtime.\n",
    "\n",
    "For breast cancer with random forest, single StratifiedKFold(5) and RepeatedStratifiedKFold(5x3) both landed around 0.990 ROC-AUC, with standard deviations in the 0.008–0.009 range and runtimes near 1–1.5 seconds. The nested CV run for random forest with feature selection (rf_fs_nested) also achieved roughly 0.990 +/- 0.008 but took over 30 seconds. The SVC model with nested stratified CV reached about 0.995 +/- 0.006 in under a second, illustrating how nested CV can still be affordable when the model and grid are relatively small.\n",
    "\n",
    "On the wine dataset, all strategies performed extremely well. Logistic regression with KFold(5) produced ROC-AUC(ovr) around 0.999 +/- 0.001, StratifiedKFold(5) essentially hit 1.000 +/- 0.000, and RepeatedKFold(5x3) gave about 1.000 +/- 0.001. Random forest with KFold(5) and RepeatedKFold(5x3) also stayed near 0.999–1.000 with very small standard deviations and sub-second runtimes. This confirms that for this small, highly separable dataset, the choice of CV strategy does not change the ranking or conclusions very much.\n",
    "\n",
    "Looking across models and datasets, the strategies with the lowest standard deviation tend to be stratified or repeated stratified CV on the breast cancer data, and simple (stratified) K-Fold on the wine data. Nested CV usually has slightly larger variance because it does a harder job: it estimates the performance of a tuned pipeline with an outer test fold that has never influenced hyperparameter choice.\n",
    "\n",
    "In terms of realism, nested stratified CV is the most trustworthy protocol for tuned models. For example, the nested logistic regression and SVC runs on breast cancer produce ROC-AUC values that are a bit lower than the non-nested scores, reflecting the fact that we are now evaluating models that have not seen their outer test folds during tuning. These are the numbers I would report if I had to make a formal claim about deployed performance.\n",
    "\n",
    "For day-to-day work, repeated stratified K-Fold is the most practical compromise. On breast cancer, it gives very similar mean ROC-AUC to single StratifiedKFold, slightly smaller or comparable standard deviations, and much faster runtimes. This makes it a good default for comparing many models, with the option to then confirm the final chosen pipeline using nested CV.\n",
    "\n",
    "Based on this table, my decision rules going forward are: \n",
    "\n",
    "1. for imbalanced classification with n < 2k, I will use StratifiedKFold or RepeatedStratifiedKFold as my baseline CV strategy\n",
    "2. whenever I am doing serious hyperparameter tuning or feature selection, I will wrap the whole pipeline in nested stratified CV to avoid leakage\n",
    "3. when I have many candidate models, I will first screen them with repeated stratified CV, then run nested CV on the top one or two models before choosing a final pipeline to deploy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37440ab2-a9f9-47b6-90cb-a99225d3a606",
   "metadata": {},
   "source": [
    "### Task 7 Markdown - Nested CV as the gold standard\n",
    "\n",
    "Nested cross validation is the gold standard because it separates tuning (inner loop) from evaluation (outer loop), so the test folds are never used to pick hyperparameters. This design prevents subtle forms of data leakage and produces a slightly lower but more honest estimate of performance for the tuned pipeline. Because the procedure is explicit about what data is “seen” during tuning vs evaluation, it is the protocol I would trust for final reporting and deployment decisions. Stratification is non negotiable whenever the target data is imbalanced or when misclassifying the minority class is costly (e.g., malignant tumors vs benign in the breast cancer dataset). Without stratification, some folds can end up with very few or even zero minority samples, which leads to inflated accuracy and unstable metrics like ROC-AUC or F1. In this lab, the breast cancer dataset generally benefited from StratifiedKFold and RepeatedStratifiedKFold, both in terms of higher mean ROC-AUC and lower variance.\n",
    "\n",
    "Repeated CV is worth the extra compute for small datasets, where a single partition can dramatically change the model ranking. By averaging over multiple random splits, repeated CV reduces the variance of the performance estimate, making it less likely that I pick the best model purely by chance. The extra compute is justified when the dataset is small and the stakes of picking the wrong model are high. Tt is less critical for very large datasets where each fold already approximates the full distribution well. In deployment, I will not re-run CV; instead, I will use a strong CV protocol such as repeated stratified cross validation or nested cross validation during training to choose and tune a single best pipeline. I will then freeze that pipeline, including preprocessing, feature selection, and hyperparameters. I will ship only that one fixed model into production, where it receives new data and outputs predictions. In other words, cross-validation would live entirely in the training/evaluation phase, while the deployment model is the final product of that CV-based selection, not a model that continues to use data from cross validation in production.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
